name: "nemo-megatron-nim"
version: "1.0"
framework: "nemo"
description: "NIM wrapper for NeMo Megatron GPT Model"

model:
  model:
    num_layers: 24
    hidden_size: 2048
    ffn_hidden_size: 8192
    num_attention_heads: 16
    max_position_embeddings: 2048
    hidden_dropout: 0.1
    attention_dropout: 0.1
    apply_query_key_layer_scaling: true
    normalization: "layernorm"
    kv_channels: null
    layernorm_epsilon: 1e-5
    bias: true
    use_rotary_position_embeddings: true
    precision: 16
    fp16: true
    bf16: false

compute:
  gpu_required: true
  memory: 16GB
  precision: 16
  accelerator: "gpu"
  devices: 1
